"""
Load Balancer for AI Services
Distributes tasks to specialized services for optimal performance
"""
from typing import Dict
from config import Config
from .ai_service import AIService


class AILoadBalancer:
    """
    Intelligent load balancer that routes requests to specialized AI services
    
    Strategy:
    - Video Processing (transcription + profile extraction): Groq (fast transcription)
    - CV Profile Generation: Gemini (high quality text)
    - Technical Test Generation: OpenRouter/Hugging Face (for companies)
    - Fallback: Any available service
    
    Note: Technical tests are generated by companies for selected candidates,
    not automatically from candidate profiles.
    """
    
    def __init__(self, services: Dict[str, AIService]):
        """
        Initialize load balancer with available services
        
        Args:
            services: Dictionary of service_name -> service_instance
        """
        self.services = services
        self.primary_services = {
            'transcription': 'groq',        # Best for audio transcription
            'profile_extraction': 'groq',   # Fast and accurate
            'cv_generation': 'groq',        # Changed to Groq (better quota than Gemini)
            'technical_test': 'groq'        # Changed to Groq (more reliable)
        }
        self.fallback_order = ['groq', 'gemini', 'openrouter', 'huggingface']
    
    def get_service_for_task(self, task: str) -> AIService:
        """
        Get the best service for a specific task
        
        Args:
            task: One of 'transcription', 'profile_extraction', 'cv_generation', 'technical_test'
        
        Returns:
            AIService instance
        """
        # Try primary service for this task
        primary_service_name = self.primary_services.get(task)
        if primary_service_name and primary_service_name in self.services:
            return self.services[primary_service_name]
        
        # Fallback to first available service
        for service_name in self.fallback_order:
            if service_name in self.services:
                service = self.services[service_name]
                
                # Check if service supports the task
                if task == 'transcription':
                    try:
                        # Only Groq and Gemini support transcription
                        if service_name in ['groq', 'gemini']:
                            return service
                    except:
                        continue
                else:
                    return service
        
        raise RuntimeError(f"No service available for task: {task}")
    
    def transcribe_audio(self, audio_path: str) -> str:
        """Route transcription to best service with fallback"""
        service = self.get_service_for_task('transcription')
        print(f"[Load Balancer] Using {type(service).__name__} for transcription")
        
        try:
            return service.transcribe_audio(audio_path)
        except Exception as e:
            error_msg = str(e)
            print(f"[Load Balancer] Error with {type(service).__name__}: {error_msg}")
            
            # Try fallback for transcription (only Groq and Gemini support it)
            if "429" in error_msg or "quota" in error_msg.lower() or "rate limit" in error_msg.lower():
                print(f"[Load Balancer] Attempting fallback for transcription...")
                
                for service_name in ['groq', 'gemini']:  # Only these support transcription
                    if service_name in self.services:
                        fallback_service = self.services[service_name]
                        if fallback_service != service:
                            try:
                                print(f"[Load Balancer] Trying {type(fallback_service).__name__}...")
                                return fallback_service.transcribe_audio(audio_path)
                            except Exception as fallback_error:
                                print(f"[Load Balancer] Fallback failed: {str(fallback_error)}")
                                continue
            
            raise e
    
    def extract_profile(self, text: str) -> dict:
        """Route profile extraction to best service with fallback"""
        service = self.get_service_for_task('profile_extraction')
        print(f"[Load Balancer] Using {type(service).__name__} for profile extraction")
        
        try:
            return service.extract_profile(text)
        except Exception as e:
            import traceback
            error_msg = str(e)
            print(f"[Load Balancer] Error with {type(service).__name__}: {error_msg}")
            print(f"[Load Balancer] Full traceback:\n{traceback.format_exc()}")
            
            # Try fallback services if quota exceeded or rate limit
            if "429" in error_msg or "quota" in error_msg.lower() or "rate limit" in error_msg.lower():
                print(f"[Load Balancer] Attempting fallback for profile extraction...")
                
                for service_name in self.fallback_order:
                    if service_name in self.services:
                        fallback_service = self.services[service_name]
                        if fallback_service != service:
                            try:
                                print(f"[Load Balancer] Trying {type(fallback_service).__name__}...")
                                return fallback_service.extract_profile(text)
                            except Exception as fallback_error:
                                print(f"[Load Balancer] Fallback failed: {str(fallback_error)}")
                                continue
            
            raise e
    
    def generate_cv_profile(self, transcription: str, profile_data: dict) -> str:
        """Route CV generation to best service with fallback"""
        service = self.get_service_for_task('cv_generation')
        print(f"[Load Balancer] Using {type(service).__name__} for CV generation")
        
        try:
            return service.generate_cv_profile(transcription, profile_data)
        except Exception as e:
            error_msg = str(e)
            print(f"[Load Balancer] Error with {type(service).__name__}: {error_msg}")
            
            # Try fallback services if quota exceeded or rate limit
            if "429" in error_msg or "quota" in error_msg.lower() or "rate limit" in error_msg.lower():
                print(f"[Load Balancer] Attempting fallback for CV generation...")
                
                # Try other services in order
                for service_name in self.fallback_order:
                    if service_name in self.services:
                        fallback_service = self.services[service_name]
                        if fallback_service != service:  # Don't retry same service
                            try:
                                print(f"[Load Balancer] Trying {type(fallback_service).__name__}...")
                                return fallback_service.generate_cv_profile(transcription, profile_data)
                            except Exception as fallback_error:
                                print(f"[Load Balancer] Fallback failed: {str(fallback_error)}")
                                continue
            
            # If all fallbacks fail, raise original error
            raise e
    
    def generate_technical_test(self, profile_data: dict) -> str:
        """Route technical test generation to best service with fallback"""
        service = self.get_service_for_task('technical_test')
        print(f"[Load Balancer] Using {type(service).__name__} for technical test generation")
        
        try:
            return service.generate_technical_test(profile_data)
        except Exception as e:
            error_msg = str(e)
            print(f"[Load Balancer] Error with {type(service).__name__}: {error_msg}")
            
            # Try fallback services if quota exceeded or rate limit
            if "429" in error_msg or "quota" in error_msg.lower() or "rate limit" in error_msg.lower():
                print(f"[Load Balancer] Attempting fallback for technical test generation...")
                
                for service_name in self.fallback_order:
                    if service_name in self.services:
                        fallback_service = self.services[service_name]
                        if fallback_service != service:
                            try:
                                print(f"[Load Balancer] Trying {type(fallback_service).__name__}...")
                                return fallback_service.generate_technical_test(profile_data)
                            except Exception as fallback_error:
                                print(f"[Load Balancer] Fallback failed: {str(fallback_error)}")
                                continue
            
            raise e
